{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkp1DJSe4c1P"
   },
   "source": [
    "## Build and Evaluate a Sentiment Classifier (Naive Bayes + Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNucKKb_pgKl",
    "outputId": "1287cf19-69fe-4e12-9972-ca1001a0ad09"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m movie_reviews\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsn9lZEYE4_H",
    "outputId": "6d17e0f6-a584-4b87-fe26-4c87fe5b7f0b"
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mlist\u001b[39m(movie_reviews\u001b[38;5;241m.\u001b[39mwords(fileid)), category)\n\u001b[1;32m----> 2\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmovie_reviews\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategories\u001b[49m()\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m movie_reviews\u001b[38;5;241m.\u001b[39mfileids(category)]\n\u001b[0;32m      5\u001b[0m docs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\corpus\\util.py:120\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:551\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    549\u001b[0m modified_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pieces[:i] \u001b[38;5;241m+\u001b[39m [pieces[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m pieces[i:])\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodified_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:538\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(p):\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mZipFilePathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzipentry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;66;03m# resource not in zipfile\u001b[39;00m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:391\u001b[0m, in \u001b[0;36mZipFilePathPointer.__init__\u001b[1;34m(self, zipfile, entry)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mCreate a new path pointer pointing at the specified entry\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03min the given zipfile.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mdoes not contain the specified entry.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(zipfile, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 391\u001b[0m     zipfile \u001b[38;5;241m=\u001b[39m \u001b[43mOpenOnDemandZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Check that the entry exists:\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m entry:\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;66;03m# Normalize the entry string, it should be relative:\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:1020\u001b[0m, in \u001b[0;36mOpenOnDemandZipFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReopenableZipFile filename must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1020\u001b[0m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m==\u001b[39m filename\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1349\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1349\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1352\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1416\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "docs = [(list(movie_reviews.words(fileid)), category)\n",
    "        for category in movie_reviews.categories()\n",
    "        for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwoo7MOSE43X",
    "outputId": "089db93d-b160-4146-9b1d-e4c94a489e4a"
   },
   "outputs": [],
   "source": [
    "random.shuffle(docs)\n",
    "\n",
    "def extract_features(words):\n",
    "    return {word: True for word in words}\n",
    "\n",
    "featuresets = [(extract_features(doc), category) for (doc, category) in docs]\n",
    "train_set, test_set = featuresets[:1500], featuresets[1500:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzrj0siI4uM8"
   },
   "source": [
    "## N-gram Phrase Extraction with Frequency Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Doe4I-Sz4eLM",
    "outputId": "9d5a7561-3c52-4917-afe6-b0057c32ffa1"
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "words = movie_reviews.words()\n",
    "finder = BigramCollocationFinder.from_words(words)\n",
    "finder.apply_freq_filter(20)\n",
    "\n",
    "print(finder.nbest(BigramAssocMeasures.pmi, 10))  # Top 10 meaningful bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIsJ65-A40Qs"
   },
   "source": [
    "## Word2Vec-based Similarity Search using NLTK Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqUzAqUR42QF",
    "outputId": "e2ccc9bd-2c80-42e6-f422-7eb1fb9fe0bb"
   },
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh4EGAeG5LjW",
    "outputId": "e82702fb-b851-4b3e-9aa5-6cc7187133ef"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v156Mxka4wVK",
    "outputId": "14ec653b-9977-45eb-ab39-f3f08646f943"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import brown\n",
    "\n",
    "sentences = brown.sents()\n",
    "model = gensim.models.Word2Vec(sentences, vector_size=100, window=5, min_count=5, sg=1)\n",
    "\n",
    "print(\"Similar to 'money':\", model.wv.most_similar(\"money\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoncNkxY46Fn"
   },
   "source": [
    "## Doc2Vec for Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oD6mx4an46kl",
    "outputId": "64ea3232-3042-4626-9be6-7f99410cd287"
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "docs = [TaggedDocument(words=movie_reviews.words(fileid), tags=[fileid])\n",
    "        for fileid in movie_reviews.fileids()]\n",
    "model = Doc2Vec(docs, vector_size=50, epochs=30)\n",
    "\n",
    "X = [model.dv[doc.tags[0]] for doc in docs]\n",
    "y = [movie_reviews.categories(fileid)[0] for fileid in movie_reviews.fileids()]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Doc2Vec Classifier Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A615nnA75Qx_"
   },
   "source": [
    "## PPMI Co-occurrence Vector Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFVNDuz14_Xq",
    "outputId": "45c56453-61da-4dd6-cdff-3eccafa7b636"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.util import bigrams\n",
    "\n",
    "text = \"dog cat bark meow dog bark meow cat\".split()\n",
    "vocab = list(set(text))\n",
    "co_matrix = Counter(bigrams(text))\n",
    "\n",
    "word_counts = Counter(text)\n",
    "ppmi_matrix = {}\n",
    "\n",
    "for (w1, w2), count in co_matrix.items():\n",
    "    p_w1 = word_counts[w1] / len(text)\n",
    "    p_w2 = word_counts[w2] / len(text)\n",
    "    p_w1_w2 = count / len(text)\n",
    "    pmi = np.log2(p_w1_w2 / (p_w1 * p_w2))\n",
    "    ppmi_matrix[(w1, w2)] = max(pmi, 0)\n",
    "\n",
    "print(\"PPMI Matrix:\", ppmi_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeySqBBc7wKz"
   },
   "source": [
    "## NER Visualization with Displacy for Legal Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNa2Skgu70he"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "twXzIHiI5Rn3",
    "outputId": "98eb8408-5235-4a89-81ec-181401d2b9cf"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(\"This Agreement is made on 4th April 2023 between Apple Inc. and John Doe.\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CVPmwEU74-T"
   },
   "source": [
    "## Custom Pattern Matching (e.g., Date + Entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "Ke3ztj3H73LF",
    "outputId": "16d9bf29-2666-4a65-c940-0d7569fc2973"
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"ENT_TYPE\": \"DATE\"}, {\"LOWER\": \"between\"}, {\"ENT_TYPE\": \"ORG\"}]\n",
    "matcher.add(\"DATE_CONTRACT_PATTERN\", [pattern])\n",
    "\n",
    "doc = nlp(\"Signed on 5th March 2024 between Microsoft and John.\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B9Q3E_p8QNC"
   },
   "source": [
    "## Text Clustering using spaCy Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKaU70wZ8T0g",
    "outputId": "41edc5d7-a36e-4bcd-d835-632acac6f92a"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "sentences = [\"The cat sits on the mat\", \"Dogs bark loudly\", \"The dog is in the yard\"]\n",
    "docs = [nlp(sent) for sent in sentences]\n",
    "X = np.array([doc.vector for doc in docs])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "for i, label in enumerate(kmeans.labels_):\n",
    "    print(f\"Cluster {label}: {sentences[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGHDjFtU8qFj"
   },
   "source": [
    "## Fine-Grained NER Training (Custom Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IedzbNXz8nNP",
    "outputId": "b2936bac-fc36-4478-c3f4-31b4bfc50a6b"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Start from a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add NER pipeline component\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "ner.add_label(\"ORG\")\n",
    "ner.add_label(\"PRODUCT\")\n",
    "\n",
    "# Create a sample training set with diverse examples\n",
    "TRAIN_DATA = [\n",
    "    (\"Apple released the new Vision Pro.\", {\"entities\": [(0, 5, \"ORG\"), (24, 34, \"PRODUCT\")]}),\n",
    "    (\"Microsoft launched Surface Laptop.\", {\"entities\": [(0, 9, \"ORG\"), (19, 34, \"PRODUCT\")]}),\n",
    "    (\"Google unveiled the Pixel 8 phone.\", {\"entities\": [(0, 6, \"ORG\"), (19, 29, \"PRODUCT\")]}),\n",
    "    (\"Apple Vision Pro is a mixed reality headset.\", {\"entities\": [(0, 5, \"ORG\"), (6, 16, \"PRODUCT\")]}),\n",
    "    (\"Amazon presented the new Echo Show 10.\", {\"entities\": [(0, 6, \"ORG\"), (25, 39, \"PRODUCT\")]}),\n",
    "]\n",
    "\n",
    "# Convert to Example objects\n",
    "examples = []\n",
    "for text, annots in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    examples.append(Example.from_dict(doc, annots))\n",
    "\n",
    "# Training loop\n",
    "optimizer = nlp.begin_training()\n",
    "for i in range(30):  # More iterations for better training\n",
    "    nlp.update(examples, sgd=optimizer)\n",
    "\n",
    "# Test\n",
    "test_doc = nlp(\"Apple introduced the Vision Pro headset today.\")\n",
    "print([(ent.text, ent.label_) for ent in test_doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uju7fv_E8rwP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
